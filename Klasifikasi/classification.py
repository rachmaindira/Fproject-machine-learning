# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-QkEk--n_1BrK9SEDThgS3zSSp0huOd

# **Import Library**
"""

#linear algebra
import pandas as pd

# data processing, CSV file I/O (e.g. pd.read_csv)
import numpy as np

# data visualization 
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
import matplotlib as mpl
mpl.rcParams['figure.dpi'] = 150

# sklearn for splitting the data
from sklearn.model_selection import train_test_split

"""# **Import Dataset**

Dataset langsung diakses ke google drive, sehingga tidak perlu mengupload dataset
"""

from google.colab import drive
drive.mount('/content/drive/')

!ls "drive/My Drive/malin"

dataset = pd.read_csv('/content/drive/My Drive/malin/used_cars.csv')

"""# **Eksplorasi dan Persiapan data**

Pada tahapan ini dilakukan cleansing data seperti menghilangkan missing value, outlier, kesalahan input, dll. Lalu  sebelum melakukan cleansing saya melakukan drop/hapus beberapa atribut yang dirasa tidak mempunyai korelasi dengan class lalu melakukan encode.

Setelah itu melakukan proses eksplorasi data untuk dilakukan tahap selanjutnya yaitu Feature Selection. Di feature selection ini dilihat atribut mana yang mempunyai korelasi/hubungan yang tinggi dengan class(title_status)
"""

dataset.drop(dataset.columns[dataset.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)
df = dataset.drop(columns=['image_url','url','description','region_url','county'])

df

"""## **Taking care missing value**

Mengganti missing value dengan mean, tetapi untuk missing value di class langsung saya hapus.
"""

df ['year'] = df['year'].replace(np.NaN , df['year'].mean())
df ['odometer'] = df['odometer'].replace(np.NaN , df['odometer'].mean())
df ['lat'] = df['lat'].replace(np.NaN , df['lat'].mean())
df ['long'] = df['long'].replace(np.NaN , df['long'].mean())

df =df.dropna(how='all', subset=['title_status'])

df = df.fillna('-')

print(df.isnull().sum())

"""## **Taking care outlier**

Melihat outlier pada data denga tipe float
"""

plt.figure()
df.boxplot(['year'])

plt.figure()
df.boxplot(['price'])

plt.figure()
df.boxplot(['odometer',])

plt.figure()
df.boxplot(['lat',])

plt.figure()
df.boxplot(['long',])

"""## **MENGHAPUS OUTLIER DI ATRIBUT PRICE**"""

df = df[df.price > 0]

"""## **Exploration data**"""

df.shape

df.dtypes

df.describe()

df.head()

"""## **Feature Selection**

sebelum melakukan feature selection, saya melakukan encode pada feature yang bertipe data object. agar bisa dilihat korelasinya dengan class
"""

kolom=df.columns.values.tolist()
for x in kolom:
    if df[x].dtype=='object':
        df[x]=df[x].astype(str)
df.dtypes

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

num={}
df_num=pd.DataFrame(num)

print(kolom)

print()
for x in kolom:
    print(x)
    df_num[x]=encoder.fit_transform(df[x])

df_num.head(10)

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
sns.set_style("whitegrid")
import matplotlib.pyplot as plt
# %matplotlib inline

mpl.rcParams['figure.dpi'] = 200
corr = df.select_dtypes(include = ['float64', 'int64']).iloc[:, :].corr()
plt.figure(figsize=(10, 10))
ax = sns.heatmap(corr, vmax=1, square=True)
# ax.set_xticklabels(rotation=30)
plt.xticks(rotation=45)
plt.yticks(rotation=45)

X = df_num.loc[:, df_num.columns != 'title_status'] #independent columns
Y = df_num.iloc[:,-10]    #target column 


from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt

model = ExtraTreesClassifier()
model.fit(X,Y)

print(model.feature_importances_) 

#plot graph of feature importances for better visualization
feat_importances = pd.Series(model.feature_importances_, index=X.columns)
feat_importances.nlargest(11).plot(kind='barh')

plt.show()

# melakukan drop pada feature yg tidak digunakan
df2 = df_num.drop(columns=['region','cylinders','fuel','transmission','drive','size','paint_color','state'])

df2

"""## **Unduh Dataset hasil eksplorasi(dataset untuk pemodelan)**"""

df2.columns = ['id','price','year','manufacturer','model','condition','odometer','title_status','vin','type','lat','long']
df2.to_csv('dataset_klasifikasi.csv',index = False)

"""# **KLASIFIKASI**"""

df2

# menentukan mana independet kolom dan target kolom(class)
X = df2.loc[:, df2.columns != 'title_status'].values
Y = df2.iloc[:,-5].values

# Lalu data dipisah menjadi 80% data training dan 20% data testing
# lalu tiap data di  X dan Y dipisah menjadi data training dan testing

train_pct_index = int(0.8 * len(X))
X_train, X_test = X[:train_pct_index], X[train_pct_index:]
Y_train, Y_test = Y[:train_pct_index], Y[train_pct_index:]

# Ditahap ini dilakukan fit antara independet kolom(train dan test) dengan library 

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Lalu dilakukan pemodelan dengan KNN

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=7)
classifier.fit(X_train, Y_train)

# dilakukan prediksi dengan Y(class) dengan hasil dari prediksi pada data testing

Y_pred = classifier.predict(X_test)

# hasil prediksi

Y_pred

"""## **Evaluasi**"""

Y_test = pd.Series(Y_test, name='Actual')
Y_pred = pd.Series(Y_pred, name='Predicted')
fitur2_confusion = pd.crosstab(Y_test, Y_pred)

fitur2_confusion

#menampilkan confusion matriks dari hasil prediksi dan nilai akurasi

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y_test, Y_pred))
print(classification_report(Y_test, Y_pred))

"""# **EKSPERIMEN**

Ditahap ini saya melakukan eksperimen, bagaimana jika tidak melakukan tahap feature selection. Sehingga pemilihan feature saya lakukan tanpa tahap feature selection. Dan semua feature digunakan dengan title_status sebagai class
"""

df_num

X1 = df_num.loc[:, df_num.columns != 'title_status'].values
Y1 = df_num.iloc[:,-10].values
Y1

train_pct_index = int(0.8 * len(X1))
X1_train, X1_test = X1[:train_pct_index], X1[train_pct_index:]
Y1_train, Y1_test = Y1[:train_pct_index], Y1[train_pct_index:]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X1_train)

X1_train = scaler.transform(X1_train)
X1_test = scaler.transform(X1_test)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=7)
classifier.fit(X1_train, Y1_train)

Y1_pred = classifier.predict(X1_test)

"""## **Evaluasi**"""

Y1_test = pd.Series(Y1_test, name='Actual')
Y1_pred = pd.Series(Y1_pred, name='Predicted')
fitur_confusion = pd.crosstab(Y1_test, Y1_pred)

fitur_confusion

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(Y1_test, Y1_pred))
print(classification_report(Y1_test, Y1_pred))