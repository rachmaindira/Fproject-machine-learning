# -*- coding: utf-8 -*-
"""clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uxkrkiH6NUUbp3YOHyqXo0P0xXsSs5jv

# **Import Library**
"""

import pandas as pd
import numpy as np
from random import sample

import matplotlib.pyplot as plt
from matplotlib import style

"""# **Import Dataset**"""

from google.colab import drive
drive.mount('/content/drive/')

!ls "drive/My Drive/malin"
data = pd.read_csv('/content/drive/My Drive/malin/used_cars.csv')
data.head(2)

"""# **Eksplorasi dan Persiapan data**

Feature yg dipakai = lat and long
"""

data ['lat'] = data['lat'].replace(np.NaN , data['lat'].mean())
data ['long'] = data['long'].replace(np.NaN , data['long'].mean())
data ['year'] = data['year'].replace(np.NaN , data['year'].mean())
data ['odometer'] = data['odometer'].replace(np.NaN , data['odometer'].mean())

data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)
#print(data)
data=data.drop('county',axis=1)
data=data.drop('size',axis=1)
data=data.drop('condition',axis=1)
data=data.drop('cylinders',axis=1)


## MISSING VALUE

data =data.dropna(how='all', subset=['title_status'])
data = data.fillna('-')
data=data.dropna()

"""## **Taking care Outlier**
Melihat outlier pada feature year dan odometer
"""

plt.figure()
data.boxplot(['price'])

plt.figure()
data.boxplot(['odometer'])

plt.figure()
data.boxplot(['lat'])

plt.figure()
data.boxplot(['long'])

#Taking care missing value, hanya di atribut price. karena atribut price tidak mungkin <= 0. sehingga data price yang <= 0 akan dihapus

data = data[data.price > 0]

print(data.isnull().sum())

kolom=data.columns.values.tolist()
print(kolom)
for x in kolom[0:-2]:
    if data[x].dtype=='object':
        #print("nice")
        data[x]=data[x].astype(str)
print(data['odometer'])
data.dtypes

"""# **Exploration Data**"""

data.shape

data.dtypes

data.describe()

data.head()

"""# **Pemodelan**

## **Visualisasi data sebelum clustering**
"""

plt.figure(figsize=(20,20))
# print(data['price'][0],data['odometer'][0])
# print(min(data['price']))
# print(max(data['price']))

# print(min(data['odometer']))
# print(max(data['odometer']))

# plt.xticks(np.arange(min(data['price']),max(data['price']),50000))
# print("ASS2")

# plt.yticks(np.arange(min(data['odometer']),max(data['odometer']),50000))
# print("ASS")
lat=(data['lat'])
long=(data['long'])
plt.scatter(lat,long)
plt.show()

"""## **Algoritma K-Means**"""

class K_Means:

    #inisiasi nilai k dan maksimum perulangan
    def __init__(self, k =3, tolerance = 0.0001, max_iterations = 500):
        self.k = k
        self.tolerance = tolerance
        self.max_iterations = max_iterations

 
    def fit(self, data):

        self.centroids = {} #membuat centroids

        #menginisiasi nilai centroid, nilai 'k' pertama pada elemen di dataset akan jadi nilai centroid
        for i in range(self.k):
            self.centroids[i] = data[i]

        #mulai iterasi
        for i in range(self.max_iterations):
            self.jarak = 0   #self.jarak untuk menghitung jarak data ke centroid
            self.classes = {}
            for i in range(self.k):
                self.classes[i] = []

            #mencari jarak antara point ke cluster, lalu memilih centroid terdekat
            for features in data:
                distances = [np.linalg.norm(features - self.centroids[centroid]) for centroid in self.centroids]
                self.jarak=self.jarak+min(distances)   #self.jarak = akan memilih jarak mana yg paling terdekat dengan centroid
                classification = distances.index(min(distances))
                self.classes[classification].append(features)

            previous = dict(self.centroids)

            #mencari nilai cluster dengan rata-rata, lalu re-calculate centroids
            for classification in self.classes:
                self.centroids[classification] = np.average(self.classes[classification], axis = 0)

            isOptimal = True

            for centroid in self.centroids:

                original_centroid = previous[centroid]
                curr = self.centroids[centroid]

                if np.sum((curr - original_centroid)/original_centroid * 100.0) > self.tolerance:
                    isOptimal = False

            #jika nilai centroid tidak terlalu berubah nilainya, maka dianggap optimal. lalu break(stop)
            if isOptimal:
                break

"""## **Hasil Cluster**"""

data_cluster=data[['lat','long']]
#print(data.dtypes)
dataset = data_cluster.astype(float).values.tolist()
X = data_cluster.values

km = K_Means(2)
km.fit(X)
X

colors = 10*["r", "g", "c", "b", "k"]
plt.figure(figsize=(20,20))

#plt.xlim(0,100000)
#plt.ylim(0,100000)

data['Cabang']=''
for classification in km.classes:
    color = colors[classification]
    for features in km.classes[classification]:
        plt.scatter(features[0], features[1], color = color,s = 10)
        #data.loc[(data['lat'] == features[0]) & (data['long'] == features[1]), 'Region'] = classification
        

        
for centroid in km.centroids:
        plt.scatter(km.centroids[centroid][0], km.centroids[centroid][1], s = 500, marker = "x")

"""# **Evaluasi**

## **ELBOW METHOD**
"""

sse = []
list_k = list(range(1,10))

for k in list_k:
  model = K_Means(k)
  model.fit(X**2)
  sse.append(model.jarak)

#plot sse
plt.figure(figsize=(6, 6))
plt.plot(list_k, sse, '-o')
plt.xlabel('Cluster(k)')
plt.ylabel('Sum Squared Error/Inertia')

"""## **nilai sse model 1**"""

#didaoat dari self.jarak pada model KM dikuadratkan
sse1=km.jarak**2
sse1

"""# **Eksperimen**

dengan mengganti nilai K= 3
"""

data_cluster2=data[['lat','long']]
#print(data.dtypes)
dataset = data_cluster.astype(float).values.tolist()
X2 = data_cluster.values

km2 = K_Means(3)
km2.fit(X2)

colors = 10*["r", "g", "c", "b", "k"]
plt.figure(figsize=(20,20))



data['Cabang']=''
for classification in km2.classes:
    color = colors[classification]
    for features in km2.classes[classification]:
        plt.scatter(features[0], features[1], color = color,s = 10)
        
for centroid in km2.centroids:
        plt.scatter(km2.centroids[centroid][0], km2.centroids[centroid][1], s = 500, marker = "x")

"""# **Evaluasi**

## **Elbow method model 2**
"""

sse = []
list_k = list(range(1,10))

for k in list_k:
  model = K_Means(k)
  model.fit(X2**2)
  sse.append(model.jarak)

#plot sse
plt.figure(figsize=(6, 6))
plt.plot(list_k, sse, '-o')
plt.xlabel('Cluster(k)')
plt.ylabel('Sum Squared Error/Inertia')

"""## **nilai sse model 2**"""

sse2 = km2.jarak**2
sse2

"""# **unduh dataset**"""

# data_cluster2=data[['lat','long']]
data_cluster2.columns = [['lat','long']]

data_cluster2.to_csv('dataset_clustering.csv',index = False)